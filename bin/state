#!/usr/bin/env python3
"""
    A commandline file consistency checker inspired by michaelosthege/gittrail

    USAGE: 
        `state -s` saves current state of files to .hashes/state.json
        `state` checks the state of files with an existing state.json

    WORKFLOW:
        Save the last known good state after processing your data
        Later, you can check the state to ensure that your input and output files are consistent
    
"""

# CONTEMPLATE: Do I need a full history of saves?
# NOTE: Doesn't prevent running git-dirty code on files
# TODO: Distinguish between input and output files? 
# TODO: Ignore binary files when archiving
# TODO: Add --ignore-files and --ignore-dirs options
# TODO: Add --compare to diff two separate state archives

import argparse
import argcomplete
import json
import sys
import tarfile
import plumbum
import magic

import difflib
from pyfzf.pyfzf import FzfPrompt

from deepdiff import DeepDiff
from hashlib import md5
from pathlib import Path
from rich import print
# from rich.columns import Columns

from datetime import datetime as dt

fzf = FzfPrompt()

STATEDIR = Path.home().joinpath('.cache/states/').joinpath(
    Path().cwd().relative_to(Path.home())
)

TIMESTAMP = dt.now().strftime("%Y-%m-%d-%H%M%S")

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('-s', '--save', nargs='?', const='', help='save state WITHOUT archive. Delete any existing archive to maintain consistency.')
    ap.add_argument('-a', '--archive', nargs='?', const='', help='save and archive state')

    ap.add_argument('-r', '--restore', action='store_true', help='restore last state from archive')
    ap.add_argument('--reset', action='store_true', help='HARD reset to last state from archive')

    ap.add_argument('-e', '--extract', action='store_true', help='extract an archive into a subfolder. Helps compare multiple archive states with binary information')

    ap.add_argument('-ls', '--list-states', action='store_true', help='list all the states (.json) available for the current directory')
    ap.add_argument('-la', '--list-archives', action='store_true', help='list all the archives (.tar.gz) available for the current directory')

    ap.add_argument('-ca', '--compare-archives', action='store_true', help='compare two of the archives (.tar.gz) available for the current directory')

    argcomplete.autocomplete(ap)
    args = ap.parse_args()

    # print(vars(args))

    FZF_FILE_OPTS = "--cycle" 

    if args.save is not None:
        save_state(args.save)
    elif args.archive is not None:
        archive_state(args.archive)
    elif args.restore:
        try: 
            selected = fzf.prompt(sorted([f.name for f in find_files(STATEDIR, suffix='.gz')], reverse=True), f"{FZF_FILE_OPTS} --prompt=\"RESTORE ❯ \"")[0]
        except plumbum.commands.processes.ProcessExecutionError: #type:ignore
            return
        statearchive = STATEDIR / selected
        restore_state(statearchive)
    elif args.reset:
        try: 
            selected = fzf.prompt(sorted([f.name for f in find_files(STATEDIR, suffix='.gz')], reverse=True), f"{FZF_FILE_OPTS} --prompt=\"RESET ❯ \"")[0]
        except plumbum.commands.processes.ProcessExecutionError: #type:ignore
            return
        statearchive = STATEDIR / selected
        reset_state(statearchive)
    elif args.list_states:
        print(sorted([f.name for f in find_files(STATEDIR, suffix='.json')], reverse=True) )
    elif args.list_archives:
        print('\n'.join(sorted([f.name for f in find_files(STATEDIR, suffix='.gz')], reverse=True)))
    elif args.compare_archives:
        compare_archives()
    elif args.extract:
        try: 
            selected = fzf.prompt(sorted([f.name for f in find_files(STATEDIR, suffix='.gz')], reverse=True), f"{FZF_FILE_OPTS} --prompt=\"RESET ❯ \"")[0]
        except plumbum.commands.processes.ProcessExecutionError: #type:ignore
            return
        statearchive = STATEDIR / selected
        extract_state(statearchive)
    else:
        check_state()

def find_files(path=Path('.'), ignore_files=[], ignore_dirs=['.git'], suffix=None):
    ignore_dirs = [Path(dir) for dir in ignore_dirs]
    ignore_files = [Path(f) for f in ignore_files]

    files = [ p for p in Path(path).rglob('*') if p.is_file() ]

    ## Ignores the statedir
    # files = list(filter(lambda f: STATEDIR not in f.parents, files))

    for dir in ignore_dirs:
        files = list(filter(lambda f: dir not in f.parents, files))
    for ignore_file in ignore_files:
        files = list(filter(lambda f: ignore_file != str(f), files))

    if suffix:
        files = list(filter(lambda f: f.suffix == suffix, files))

    return files


def read_state() -> dict:
    files = find_files()
    hashes = {}
    for ifile in files: 
        with open(ifile, 'rb') as fp:
            hash = md5(fp.read()).hexdigest()
            hashes.update({str(ifile) : hash})
    return hashes

def save_state(name):
    STATEDIR.mkdir(parents=True, exist_ok=True)

    filename = f"{TIMESTAMP}_{name}.json" if name else f"{TIMESTAMP}.json"
    archivename =  f"{TIMESTAMP}_{name}.tar.gz" if name else f"{TIMESTAMP}.tar.gz"
    statefile = STATEDIR / filename
    statearchive = STATEDIR / archivename

    hashes = read_state()
    with open(statefile, 'w') as fp:
        json.dump(hashes, fp, indent=4)

    ## Remove the archive, if any, to avoid inconsistent archive and save states
    try: 
        statearchive.unlink()
    except FileNotFoundError:
        pass

    return hashes

def archive_state(name):
    hashes = save_state(name)

    archivename = f"{TIMESTAMP}_{name}.tar.gz" if name else f"{TIMESTAMP}.tar.gz"
    statearchive = STATEDIR / archivename

    with tarfile.open(statearchive, 'w:gz') as tar:
        for key in hashes:
            tar.add(key)

def reset_state(statearchive):
    if not statearchive.is_file():
        raise(RuntimeError('state archive not found!'))

    files = find_files()
    for f in files:
        f.unlink()

    restore_state(statearchive)

def restore_state(statearchive):
    with tarfile.open(statearchive, 'r:gz') as tar:
        tar.extractall(Path('.'))

def extract_state(statearchive):
    with tarfile.open(statearchive, 'r:gz') as tar:
        tar.extractall(Path('.') / statearchive.name.rstrip('.tar.gz'))


# TODO: Change to check_last_state
# TODO: Create check_state that can check against any state/archive
def check_state():
    hashes_files = read_state()

    files = find_files(STATEDIR, suffix='.json')
    last_modified_statefile = max(files, key=lambda p: p.stat().st_ctime)
    print(f"Checking against {last_modified_statefile.name}")

    with open(last_modified_statefile) as fp:
        hashes_saved = json.load(fp)

    last_modified_statearchive = last_modified_statefile.with_suffix('.tar.gz')
    my_fancy_diff(hashes_saved, hashes_files, path1=last_modified_statearchive, path2=Path('.'))

def my_fancy_diff(state1, state2, path1=None, path2=None):
    diff = DeepDiff(state1, state2)
    if diff:
        if 'dictionary_item_added' in diff:
            # added   = Columns([ x[6:-2] for x in  diff['dictionary_item_added'] ] , equal=False, expand=True)
            added = [ x[6:-2] for x in  diff['dictionary_item_added'] ]
            print("[green]ADDED[/green]:", *added)
        if 'dictionary_item_removed' in diff:
            # removed = Columns([ x[6:-2] for x in  diff['dictionary_item_removed'] ] , equal=False, expand=True)
            removed = [ x[6:-2] for x in  diff['dictionary_item_removed'] ]
            print("[red]REMOVED[/red]:", *removed)
        if 'values_changed' in diff:
            # changed = Columns([ x[6:-2] for x in  diff['dictionary_item_changed'] ] , equal=True, expand=True)
            changed = { x[6:-2]:diff['values_changed'][x]  for x in  diff['values_changed'] }
            print("[yellow]CHANGED[/yellow]:", *changed)

            if path1.is_file() and path1.suffix == '.gz':
                with tarfile.open(path1, 'r:gz') as tar:
                    tar.extractall(Path('/tmp') / "path1", members=[x for x in tar.getmembers() if x.name in changed])
                path1 = Path("/tmp/path1")

            if path2.is_file() and path2.suffix == '.gz':
                with tarfile.open(path2, 'r:gz') as tar:
                    tar.extractall(Path('/tmp') / "path2", members=[x for x in tar.getmembers() if x.name in changed])
                path2 = Path("/tmp/path2")
                
            mime = magic.Magic(mime=True)
            allowed_types = ['text/plain', 'text/csv', 'application/json']

            for changed_file in changed:
                mimetype = mime.from_file(str(path1 / changed_file))
                if mimetype in allowed_types:
                    with open(path1 / changed_file, 'r') as fp:
                        oldfile = fp.read().split('\n')
                    with open(path2 / changed_file, 'r') as fp:
                        newfile = fp.read().split('\n')
                    out = list(difflib.unified_diff(oldfile, newfile, fromfile=str(path1/changed_file), tofile=str(path2/changed_file), n=0))
                    for line in out:
                        if line[0] == '-': 
                            print('[red]' + line)
                        if line[0] == '+': 
                            print('[green]' + line)
        sys.exit(-1)
    else:
        print("Clean!")
            
def compare_archives():
    FZF_FILE_OPTS = "--cycle --multi" 
    try: 
        selected = fzf.prompt(sorted([f.name for f in find_files(STATEDIR, suffix='.gz')], reverse=True), f"{FZF_FILE_OPTS} --prompt=\"COMPARE❯ \"")
    except plumbum.commands.processes.ProcessExecutionError: #type:ignore
        sys.exit(-1)

    if len(selected) != 2:
        raise RuntimeError("Can only compare two archives at once!")

    path1 = STATEDIR / selected[0]
    path2 = STATEDIR / selected[1]

    statefile1 = path1.with_suffix('').with_suffix('.json')
    statefile2 = path2.with_suffix('').with_suffix('.json')

    with open(statefile1, 'r') as fp:
        state1 = json.load(fp)

    with open(statefile2, 'r') as fp:
        state2 = json.load(fp)

    my_fancy_diff(state1, state2, path1=path1, path2=path2)


if __name__ == "__main__":
    main()
